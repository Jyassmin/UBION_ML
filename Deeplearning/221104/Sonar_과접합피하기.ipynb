{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과적합 피하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Lib & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.2238</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.3914</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4   ...      56      57      58      59  60\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "numpy.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 데이터 입력\n",
    "df = pd.read_csv(\"../datasets/sonar.csv\", header=None)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. 초기 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 X, Y(split, LE) - 1. 이후에도 계속 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, Y_obj Split(slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe(df)는 iloc로 슬라이싱해서 Dataframe 반환\n",
    "# df.values는 Dataframe을 array로 반환.\n",
    "## array는 [:, 0:60]로 0~59열 슬라이싱 가능\n",
    "dataset=df.values\n",
    "X = dataset[:,:60]\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "Y_obj = dataset[:, 60]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label 문자열 반환\n",
    "le = LabelEncoder()\n",
    "le.fit(Y_obj)\n",
    "Y = le.transform(Y_obj)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "            optimizer=\"adam\",\n",
    "            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 849us/step - loss: 0.6829 - accuracy: 0.5577\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 783us/step - loss: 0.6691 - accuracy: 0.7837\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 762us/step - loss: 0.6541 - accuracy: 0.7548\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 801us/step - loss: 0.6290 - accuracy: 0.7740\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 769us/step - loss: 0.5993 - accuracy: 0.7788\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 812us/step - loss: 0.5745 - accuracy: 0.7404\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 710us/step - loss: 0.5412 - accuracy: 0.7885\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 929us/step - loss: 0.5126 - accuracy: 0.7692\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 791us/step - loss: 0.4999 - accuracy: 0.7596\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 777us/step - loss: 0.4743 - accuracy: 0.8125\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 737us/step - loss: 0.4650 - accuracy: 0.8125\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 757us/step - loss: 0.4398 - accuracy: 0.7981\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 731us/step - loss: 0.4284 - accuracy: 0.8221\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.4174 - accuracy: 0.8077\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 774us/step - loss: 0.4073 - accuracy: 0.8173\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 760us/step - loss: 0.4046 - accuracy: 0.8317\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 824us/step - loss: 0.3899 - accuracy: 0.8221\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.3855 - accuracy: 0.8269\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 780us/step - loss: 0.3840 - accuracy: 0.8413\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 744us/step - loss: 0.3713 - accuracy: 0.8413\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 718us/step - loss: 0.3652 - accuracy: 0.8462\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8221\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.3427 - accuracy: 0.8510\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 755us/step - loss: 0.3443 - accuracy: 0.8606\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 738us/step - loss: 0.3371 - accuracy: 0.8606\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 713us/step - loss: 0.3301 - accuracy: 0.8510\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 714us/step - loss: 0.3352 - accuracy: 0.8750\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.3246 - accuracy: 0.8462\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 687us/step - loss: 0.3180 - accuracy: 0.8702\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.3108 - accuracy: 0.8798\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 715us/step - loss: 0.3043 - accuracy: 0.8654\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 769us/step - loss: 0.3122 - accuracy: 0.8990\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 721us/step - loss: 0.2907 - accuracy: 0.8942\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 730us/step - loss: 0.2987 - accuracy: 0.8654\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 698us/step - loss: 0.2831 - accuracy: 0.8894\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 724us/step - loss: 0.2841 - accuracy: 0.8798\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 714us/step - loss: 0.2770 - accuracy: 0.9087\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 733us/step - loss: 0.2772 - accuracy: 0.8942\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.2658 - accuracy: 0.9183\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 670us/step - loss: 0.2621 - accuracy: 0.9231\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 693us/step - loss: 0.2703 - accuracy: 0.8942\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 690us/step - loss: 0.2518 - accuracy: 0.9038\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 789us/step - loss: 0.2638 - accuracy: 0.8990\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 753us/step - loss: 0.2639 - accuracy: 0.9135\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.9135\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.2409 - accuracy: 0.9183\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 700us/step - loss: 0.2351 - accuracy: 0.9183\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 708us/step - loss: 0.2475 - accuracy: 0.9183\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 787us/step - loss: 0.2371 - accuracy: 0.9135\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 811us/step - loss: 0.2326 - accuracy: 0.9279\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 714us/step - loss: 0.2244 - accuracy: 0.9279\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 743us/step - loss: 0.2159 - accuracy: 0.9279\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 680us/step - loss: 0.2253 - accuracy: 0.9135\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 686us/step - loss: 0.2188 - accuracy: 0.9135\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 813us/step - loss: 0.2240 - accuracy: 0.9183\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 680us/step - loss: 0.2113 - accuracy: 0.9327\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 725us/step - loss: 0.2029 - accuracy: 0.9375\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.2057 - accuracy: 0.9231\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 708us/step - loss: 0.2055 - accuracy: 0.9375\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 706us/step - loss: 0.1995 - accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 709us/step - loss: 0.2013 - accuracy: 0.9279\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 715us/step - loss: 0.2118 - accuracy: 0.9231\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.1830 - accuracy: 0.9519\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 690us/step - loss: 0.1830 - accuracy: 0.9423\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 686us/step - loss: 0.1746 - accuracy: 0.9423\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 677us/step - loss: 0.1815 - accuracy: 0.9471\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 727us/step - loss: 0.1893 - accuracy: 0.9423\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 741us/step - loss: 0.1731 - accuracy: 0.9327\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 701us/step - loss: 0.1730 - accuracy: 0.9423\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.1617 - accuracy: 0.9615\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 711us/step - loss: 0.1642 - accuracy: 0.9567\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 741us/step - loss: 0.1661 - accuracy: 0.9519\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 692us/step - loss: 0.1577 - accuracy: 0.9519\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 787us/step - loss: 0.1586 - accuracy: 0.9471\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 689us/step - loss: 0.1534 - accuracy: 0.9567\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 678us/step - loss: 0.1507 - accuracy: 0.9375\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 736us/step - loss: 0.1522 - accuracy: 0.9471\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 698us/step - loss: 0.1437 - accuracy: 0.9615\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 702us/step - loss: 0.1448 - accuracy: 0.9567\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.1320 - accuracy: 0.9615\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 715us/step - loss: 0.1401 - accuracy: 0.9471\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 703us/step - loss: 0.1422 - accuracy: 0.9471\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 709us/step - loss: 0.1315 - accuracy: 0.9712\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 680us/step - loss: 0.1291 - accuracy: 0.9567\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 690us/step - loss: 0.1254 - accuracy: 0.9712\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 729us/step - loss: 0.1240 - accuracy: 0.9663\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.1169 - accuracy: 0.9615\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 707us/step - loss: 0.1410 - accuracy: 0.9423\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.1168 - accuracy: 0.9663\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 693us/step - loss: 0.1178 - accuracy: 0.9615\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.1079 - accuracy: 0.9663\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 688us/step - loss: 0.1226 - accuracy: 0.9423\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 687us/step - loss: 0.1134 - accuracy: 0.9567\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 693us/step - loss: 0.1047 - accuracy: 0.9712\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 706us/step - loss: 0.1023 - accuracy: 0.9712\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 817us/step - loss: 0.0978 - accuracy: 0.9760\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 762us/step - loss: 0.0984 - accuracy: 0.9663\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.0958 - accuracy: 0.9663\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 718us/step - loss: 0.0954 - accuracy: 0.9808\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 701us/step - loss: 0.0910 - accuracy: 0.9663\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 698us/step - loss: 0.0841 - accuracy: 0.9712\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 724us/step - loss: 0.0812 - accuracy: 0.9856\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 702us/step - loss: 0.0828 - accuracy: 0.9712\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 697us/step - loss: 0.0836 - accuracy: 0.9663\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 705us/step - loss: 0.0775 - accuracy: 0.9760\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 697us/step - loss: 0.0776 - accuracy: 0.9856\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.0751 - accuracy: 0.9760\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 761us/step - loss: 0.0685 - accuracy: 0.9856\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 689us/step - loss: 0.0723 - accuracy: 0.9760\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 718us/step - loss: 0.0958 - accuracy: 0.9567\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 725us/step - loss: 0.0743 - accuracy: 0.9856\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 707us/step - loss: 0.0613 - accuracy: 0.9856\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 698us/step - loss: 0.0642 - accuracy: 0.9808\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.0585 - accuracy: 0.9904\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 678us/step - loss: 0.0563 - accuracy: 0.9856\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.0538 - accuracy: 0.9904\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 818us/step - loss: 0.0534 - accuracy: 0.9952\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 695us/step - loss: 0.0538 - accuracy: 0.9952\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 700us/step - loss: 0.0520 - accuracy: 0.9856\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 685us/step - loss: 0.0517 - accuracy: 0.9904\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 745us/step - loss: 0.0575 - accuracy: 0.9952\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 704us/step - loss: 0.0454 - accuracy: 0.9952\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 717us/step - loss: 0.0493 - accuracy: 0.9904\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 710us/step - loss: 0.0390 - accuracy: 0.9952\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 707us/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 719us/step - loss: 0.0432 - accuracy: 0.9904\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 717us/step - loss: 0.0404 - accuracy: 0.9952\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 678us/step - loss: 0.0432 - accuracy: 0.9904\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 690us/step - loss: 0.0351 - accuracy: 0.9952\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 739us/step - loss: 0.0347 - accuracy: 0.9952\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 717us/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 702us/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 789us/step - loss: 0.0292 - accuracy: 0.9952\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 703us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 686us/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 689us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 691us/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 725us/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 685us/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 715us/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 683us/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 686us/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 697us/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 824us/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 762us/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 755us/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 714us/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 709us/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 719us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 713us/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 692us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 730us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 717us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 812us/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 665us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 735us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 801us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 727us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 696us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 737us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 697us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 692us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 720us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 693us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 829us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 718us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 719us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 690us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 713us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 720us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 703us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 739us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 704us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 707us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 679us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 723us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 858us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 691us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 691us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 721us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 722us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 721us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 710us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 718us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 696us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 713us/step - loss: 0.0030 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "\n",
      " Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "acc = history.history[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss, label=\"loss\")\n",
    "plt.plot(acc, label=\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"303\" alt=\"image\" src=\"https://user-images.githubusercontent.com/88031549/199865292-e5af6ce0-1563-4e1d-8037-584880321534.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. 과적합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 은닉층 수로 과접합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"377\" alt=\"image\" src=\"https://user-images.githubusercontent.com/88031549/199865363-30660e13-848e-41f4-9502-694dc5f63333.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 prameter 중 epoch으로 과접합 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 0s 872us/step - loss: 0.2575 - accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 729us/step - loss: 0.2490 - accuracy: 0.5034\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.5448\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.2435 - accuracy: 0.5793\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 866us/step - loss: 0.2401 - accuracy: 0.6069\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.2344 - accuracy: 0.6897\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.2272 - accuracy: 0.7172\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 730us/step - loss: 0.2212 - accuracy: 0.7241\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.2148 - accuracy: 0.7241\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 785us/step - loss: 0.2111 - accuracy: 0.6897\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.1995 - accuracy: 0.7172\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.1921 - accuracy: 0.7379\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.1865 - accuracy: 0.7103\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.1795 - accuracy: 0.7172\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 850us/step - loss: 0.1741 - accuracy: 0.7379\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.1667 - accuracy: 0.7655\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.1624 - accuracy: 0.7793\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1558 - accuracy: 0.7862\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.1557 - accuracy: 0.7862\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 728us/step - loss: 0.1482 - accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.1448 - accuracy: 0.8414\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.1412 - accuracy: 0.8000\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1392 - accuracy: 0.8207\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.1354 - accuracy: 0.8069\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.1376 - accuracy: 0.7931\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.1319 - accuracy: 0.8276\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.1293 - accuracy: 0.8000\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 781us/step - loss: 0.1258 - accuracy: 0.8552\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 743us/step - loss: 0.1245 - accuracy: 0.8483\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 758us/step - loss: 0.1263 - accuracy: 0.8276\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1226 - accuracy: 0.8483\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1211 - accuracy: 0.8414\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.1178 - accuracy: 0.8552\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1172 - accuracy: 0.8345\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1166 - accuracy: 0.8483\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.1132 - accuracy: 0.8483\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.1120 - accuracy: 0.8414\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 719us/step - loss: 0.1106 - accuracy: 0.8483\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.1085 - accuracy: 0.8552\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.1103 - accuracy: 0.8690\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.1100 - accuracy: 0.8552\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.1064 - accuracy: 0.8414\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.1073 - accuracy: 0.8414\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.1030 - accuracy: 0.8483\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.1010 - accuracy: 0.8552\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 784us/step - loss: 0.1003 - accuracy: 0.8621\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.1000 - accuracy: 0.8621\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.0969 - accuracy: 0.8552\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 810us/step - loss: 0.0952 - accuracy: 0.8552\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0972 - accuracy: 0.8759\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 759us/step - loss: 0.2480 - accuracy: 0.5241\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 795us/step - loss: 0.2358 - accuracy: 0.6138\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.2313 - accuracy: 0.6345\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 724us/step - loss: 0.2235 - accuracy: 0.6552\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.2160 - accuracy: 0.6552\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 650us/step - loss: 0.2061 - accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.1971 - accuracy: 0.7103\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.1880 - accuracy: 0.7655\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.1797 - accuracy: 0.7310\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.1769 - accuracy: 0.7517\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 757us/step - loss: 0.1661 - accuracy: 0.8138\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.1632 - accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.1598 - accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.1500 - accuracy: 0.7931\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.1449 - accuracy: 0.7862\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.1379 - accuracy: 0.8552\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.1377 - accuracy: 0.8276\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.1306 - accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 647us/step - loss: 0.1304 - accuracy: 0.8621\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 764us/step - loss: 0.1209 - accuracy: 0.8690\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.1185 - accuracy: 0.8828\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.1180 - accuracy: 0.8552\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.1126 - accuracy: 0.8552\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1103 - accuracy: 0.8621\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.1112 - accuracy: 0.8552\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.1063 - accuracy: 0.8690\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.1041 - accuracy: 0.8690\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.1005 - accuracy: 0.8759\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0984 - accuracy: 0.8966\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.1009 - accuracy: 0.8897\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 652us/step - loss: 0.1013 - accuracy: 0.8690\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0957 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0914 - accuracy: 0.8828\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0904 - accuracy: 0.8828\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0881 - accuracy: 0.8759\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 707us/step - loss: 0.0867 - accuracy: 0.9034\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.0848 - accuracy: 0.8897\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0835 - accuracy: 0.8897\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0818 - accuracy: 0.9034\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0857 - accuracy: 0.9034\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0824 - accuracy: 0.8966\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.0804 - accuracy: 0.8966\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0822 - accuracy: 0.8759\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0776 - accuracy: 0.9103\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.0731 - accuracy: 0.9172\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.0738 - accuracy: 0.9034\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0717 - accuracy: 0.9103\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0699 - accuracy: 0.9172\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0661 - accuracy: 0.9172\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0706 - accuracy: 0.9172\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0693 - accuracy: 0.9241\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.0656 - accuracy: 0.9379\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0649 - accuracy: 0.9172\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0609 - accuracy: 0.9379\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0637 - accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.0594 - accuracy: 0.9379\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.0587 - accuracy: 0.9379\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0592 - accuracy: 0.9448\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0570 - accuracy: 0.9448\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 643us/step - loss: 0.0558 - accuracy: 0.9448\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0540 - accuracy: 0.9448\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0548 - accuracy: 0.9517\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 866us/step - loss: 0.0523 - accuracy: 0.9448\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.0511 - accuracy: 0.9586\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0509 - accuracy: 0.9517\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0514 - accuracy: 0.9448\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0470 - accuracy: 0.9586\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0474 - accuracy: 0.9655\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 654us/step - loss: 0.0460 - accuracy: 0.9448\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0549 - accuracy: 0.9379\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0433 - accuracy: 0.9655\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0424 - accuracy: 0.9586\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.0485 - accuracy: 0.9241\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 714us/step - loss: 0.0419 - accuracy: 0.9655\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0410 - accuracy: 0.9655\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0425 - accuracy: 0.9724\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0419 - accuracy: 0.9517\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0446 - accuracy: 0.9448\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.0398 - accuracy: 0.9655\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 795us/step - loss: 0.0379 - accuracy: 0.9655\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0344 - accuracy: 0.9793\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0435 - accuracy: 0.9655\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0401 - accuracy: 0.9586\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0356 - accuracy: 0.9517\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0313 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 667us/step - loss: 0.0300 - accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 782us/step - loss: 0.0310 - accuracy: 0.9724\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0310 - accuracy: 0.9793\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0281 - accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0310 - accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0385 - accuracy: 0.9586\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0343 - accuracy: 0.9586\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0313 - accuracy: 0.9655\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0253 - accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0271 - accuracy: 0.9793\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.0245 - accuracy: 0.9931\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0239 - accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0262 - accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 716us/step - loss: 0.0233 - accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 640us/step - loss: 0.0220 - accuracy: 0.9931\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.8571\n",
      "Epoch 1/130\n",
      "29/29 [==============================] - 0s 794us/step - loss: 0.2471 - accuracy: 0.5655\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.2362 - accuracy: 0.6414\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.2298 - accuracy: 0.6621\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.2203 - accuracy: 0.7241\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 649us/step - loss: 0.2121 - accuracy: 0.7310\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.2036 - accuracy: 0.7310\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.1941 - accuracy: 0.7448\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.1869 - accuracy: 0.7586\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1794 - accuracy: 0.7724\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 852us/step - loss: 0.1760 - accuracy: 0.7793\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 653us/step - loss: 0.1677 - accuracy: 0.7931\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.1670 - accuracy: 0.7724\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.1600 - accuracy: 0.7793\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.1540 - accuracy: 0.7862\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.1506 - accuracy: 0.8069\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.1453 - accuracy: 0.8276\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1410 - accuracy: 0.8276\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1343 - accuracy: 0.8483\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.1355 - accuracy: 0.8483\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.1278 - accuracy: 0.8621\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.1249 - accuracy: 0.8759\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.1223 - accuracy: 0.8552\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1182 - accuracy: 0.8621\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.1163 - accuracy: 0.8621\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.1125 - accuracy: 0.8690\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.1095 - accuracy: 0.8966\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.1067 - accuracy: 0.8621\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1034 - accuracy: 0.8897\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.1004 - accuracy: 0.8966\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 737us/step - loss: 0.1004 - accuracy: 0.8828\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 724us/step - loss: 0.0991 - accuracy: 0.8759\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.0945 - accuracy: 0.9172\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 714us/step - loss: 0.0918 - accuracy: 0.9172\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0887 - accuracy: 0.9241\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 785us/step - loss: 0.0913 - accuracy: 0.8897\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9103\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 777us/step - loss: 0.0811 - accuracy: 0.9241\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.0789 - accuracy: 0.9241\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 766us/step - loss: 0.0763 - accuracy: 0.9172\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 815us/step - loss: 0.0796 - accuracy: 0.9241\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 718us/step - loss: 0.0732 - accuracy: 0.9241\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 842us/step - loss: 0.0709 - accuracy: 0.9310\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 773us/step - loss: 0.0687 - accuracy: 0.9310\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.0681 - accuracy: 0.9379\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.0633 - accuracy: 0.9448\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 758us/step - loss: 0.0613 - accuracy: 0.9310\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.0586 - accuracy: 0.9448\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.0576 - accuracy: 0.9448\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0533 - accuracy: 0.9724\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0555 - accuracy: 0.9448\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 809us/step - loss: 0.0559 - accuracy: 0.9448\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0495 - accuracy: 0.9586\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.0502 - accuracy: 0.9517\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.0441 - accuracy: 0.9724\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0449 - accuracy: 0.9724\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 727us/step - loss: 0.0414 - accuracy: 0.9862\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0406 - accuracy: 0.9655\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0396 - accuracy: 0.9724\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0392 - accuracy: 0.9862\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0357 - accuracy: 0.9793\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0328 - accuracy: 0.9793\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0365 - accuracy: 0.9862\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0314 - accuracy: 0.9724\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0294 - accuracy: 0.9862\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0313 - accuracy: 0.9724\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0318 - accuracy: 0.9724\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0249 - accuracy: 0.9931\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 793us/step - loss: 0.0242 - accuracy: 0.9931\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0275 - accuracy: 0.9931\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 759us/step - loss: 0.0228 - accuracy: 0.9931\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0212 - accuracy: 0.9931\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0236 - accuracy: 0.9862\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0199 - accuracy: 0.9931\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0183 - accuracy: 0.9931\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0186 - accuracy: 0.9931\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.0183 - accuracy: 0.9931\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0171 - accuracy: 0.9931\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 779us/step - loss: 0.0172 - accuracy: 0.9862\n",
      "Epoch 81/130\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.0175 - accuracy: 0.9931\n",
      "Epoch 83/130\n",
      "29/29 [==============================] - 0s 777us/step - loss: 0.0161 - accuracy: 0.9931\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0136 - accuracy: 0.9931\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0127 - accuracy: 0.9931\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0133 - accuracy: 0.9931\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0108 - accuracy: 0.9931\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 701us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 738us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 647us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 852us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 705us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 736us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 840us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 652us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 658us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 790us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 649us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.8095\n",
      "Epoch 1/150\n",
      "29/29 [==============================] - 0s 778us/step - loss: 0.2468 - accuracy: 0.5517\n",
      "Epoch 2/150\n",
      "29/29 [==============================] - 0s 758us/step - loss: 0.2373 - accuracy: 0.6207\n",
      "Epoch 3/150\n",
      "29/29 [==============================] - 0s 989us/step - loss: 0.2288 - accuracy: 0.6621\n",
      "Epoch 4/150\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.2203 - accuracy: 0.6552\n",
      "Epoch 5/150\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.2101 - accuracy: 0.7103\n",
      "Epoch 6/150\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.2017 - accuracy: 0.7103\n",
      "Epoch 7/150\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.1941 - accuracy: 0.7172\n",
      "Epoch 8/150\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.1875 - accuracy: 0.7379\n",
      "Epoch 9/150\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.1811 - accuracy: 0.7241\n",
      "Epoch 10/150\n",
      "29/29 [==============================] - 0s 756us/step - loss: 0.1787 - accuracy: 0.7379\n",
      "Epoch 11/150\n",
      "29/29 [==============================] - 0s 817us/step - loss: 0.1709 - accuracy: 0.8000\n",
      "Epoch 12/150\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.1679 - accuracy: 0.7724\n",
      "Epoch 13/150\n",
      "29/29 [==============================] - 0s 736us/step - loss: 0.1631 - accuracy: 0.7655\n",
      "Epoch 14/150\n",
      "29/29 [==============================] - 0s 763us/step - loss: 0.1587 - accuracy: 0.7931\n",
      "Epoch 15/150\n",
      "29/29 [==============================] - 0s 714us/step - loss: 0.1540 - accuracy: 0.8207\n",
      "Epoch 16/150\n",
      "29/29 [==============================] - 0s 721us/step - loss: 0.1503 - accuracy: 0.8138\n",
      "Epoch 17/150\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.1460 - accuracy: 0.8345\n",
      "Epoch 18/150\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.1410 - accuracy: 0.8207\n",
      "Epoch 19/150\n",
      "29/29 [==============================] - 0s 650us/step - loss: 0.1415 - accuracy: 0.8138\n",
      "Epoch 20/150\n",
      "29/29 [==============================] - 0s 802us/step - loss: 0.1341 - accuracy: 0.8276\n",
      "Epoch 21/150\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.1322 - accuracy: 0.8414\n",
      "Epoch 22/150\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.1318 - accuracy: 0.8414\n",
      "Epoch 23/150\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.1267 - accuracy: 0.8345\n",
      "Epoch 24/150\n",
      "29/29 [==============================] - 0s 747us/step - loss: 0.1240 - accuracy: 0.8621\n",
      "Epoch 25/150\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.1236 - accuracy: 0.8483\n",
      "Epoch 26/150\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1208 - accuracy: 0.8966\n",
      "Epoch 27/150\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.1171 - accuracy: 0.8483\n",
      "Epoch 28/150\n",
      "29/29 [==============================] - 0s 832us/step - loss: 0.1147 - accuracy: 0.8759\n",
      "Epoch 29/150\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.1125 - accuracy: 0.8897\n",
      "Epoch 30/150\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.1155 - accuracy: 0.8690\n",
      "Epoch 31/150\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1132 - accuracy: 0.8690\n",
      "Epoch 32/150\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.1101 - accuracy: 0.9034\n",
      "Epoch 33/150\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.1061 - accuracy: 0.8897\n",
      "Epoch 34/150\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.1051 - accuracy: 0.8897\n",
      "Epoch 35/150\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1036 - accuracy: 0.8897\n",
      "Epoch 36/150\n",
      "29/29 [==============================] - 0s 862us/step - loss: 0.0990 - accuracy: 0.8966\n",
      "Epoch 37/150\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0964 - accuracy: 0.8966\n",
      "Epoch 38/150\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0964 - accuracy: 0.8897\n",
      "Epoch 39/150\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.0943 - accuracy: 0.9103\n",
      "Epoch 40/150\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0948 - accuracy: 0.8897\n",
      "Epoch 41/150\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0956 - accuracy: 0.9034\n",
      "Epoch 42/150\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0927 - accuracy: 0.8897\n",
      "Epoch 43/150\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0955 - accuracy: 0.8828\n",
      "Epoch 44/150\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0879 - accuracy: 0.9034\n",
      "Epoch 45/150\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.0841 - accuracy: 0.8966\n",
      "Epoch 46/150\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.0844 - accuracy: 0.9172\n",
      "Epoch 47/150\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0815 - accuracy: 0.9103\n",
      "Epoch 48/150\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0817 - accuracy: 0.8966\n",
      "Epoch 49/150\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0778 - accuracy: 0.9034\n",
      "Epoch 50/150\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0814 - accuracy: 0.9172\n",
      "Epoch 51/150\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0784 - accuracy: 0.9103\n",
      "Epoch 52/150\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.0745 - accuracy: 0.9103\n",
      "Epoch 53/150\n",
      "29/29 [==============================] - 0s 814us/step - loss: 0.0744 - accuracy: 0.9172\n",
      "Epoch 54/150\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0703 - accuracy: 0.9172\n",
      "Epoch 55/150\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0740 - accuracy: 0.9310\n",
      "Epoch 56/150\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0687 - accuracy: 0.9241\n",
      "Epoch 57/150\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.0666 - accuracy: 0.9310\n",
      "Epoch 58/150\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0663 - accuracy: 0.9241\n",
      "Epoch 59/150\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.0646 - accuracy: 0.9379\n",
      "Epoch 60/150\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.0631 - accuracy: 0.9241\n",
      "Epoch 61/150\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0606 - accuracy: 0.9448\n",
      "Epoch 62/150\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0594 - accuracy: 0.9448\n",
      "Epoch 63/150\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0576 - accuracy: 0.9448\n",
      "Epoch 64/150\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.0552 - accuracy: 0.9586\n",
      "Epoch 65/150\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0569 - accuracy: 0.9379\n",
      "Epoch 66/150\n",
      "29/29 [==============================] - 0s 826us/step - loss: 0.0542 - accuracy: 0.9517\n",
      "Epoch 67/150\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.0506 - accuracy: 0.9586\n",
      "Epoch 68/150\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0522 - accuracy: 0.9586\n",
      "Epoch 69/150\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.0492 - accuracy: 0.9448\n",
      "Epoch 70/150\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0518 - accuracy: 0.9724\n",
      "Epoch 71/150\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0454 - accuracy: 0.9586\n",
      "Epoch 72/150\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0437 - accuracy: 0.9586\n",
      "Epoch 73/150\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0486 - accuracy: 0.9517\n",
      "Epoch 74/150\n",
      "29/29 [==============================] - 0s 878us/step - loss: 0.0438 - accuracy: 0.9586\n",
      "Epoch 75/150\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0424 - accuracy: 0.9655\n",
      "Epoch 76/150\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.0423 - accuracy: 0.9655\n",
      "Epoch 77/150\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0418 - accuracy: 0.9586\n",
      "Epoch 78/150\n",
      "29/29 [==============================] - 0s 645us/step - loss: 0.0404 - accuracy: 0.9655\n",
      "Epoch 79/150\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0398 - accuracy: 0.9724\n",
      "Epoch 80/150\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.0359 - accuracy: 0.9655\n",
      "Epoch 81/150\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.0345 - accuracy: 0.9724\n",
      "Epoch 82/150\n",
      "29/29 [==============================] - 0s 792us/step - loss: 0.0390 - accuracy: 0.9655\n",
      "Epoch 83/150\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0370 - accuracy: 0.9655\n",
      "Epoch 84/150\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0321 - accuracy: 0.9724\n",
      "Epoch 85/150\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0297 - accuracy: 0.9793\n",
      "Epoch 86/150\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0290 - accuracy: 0.9724\n",
      "Epoch 87/150\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0290 - accuracy: 0.9862\n",
      "Epoch 88/150\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.0274 - accuracy: 0.9862\n",
      "Epoch 89/150\n",
      "29/29 [==============================] - 0s 792us/step - loss: 0.0258 - accuracy: 0.9862\n",
      "Epoch 90/150\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0287 - accuracy: 0.9793\n",
      "Epoch 91/150\n",
      "29/29 [==============================] - 0s 904us/step - loss: 0.0334 - accuracy: 0.9724\n",
      "Epoch 92/150\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9655\n",
      "Epoch 93/150\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 94/150\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0210 - accuracy: 0.9931\n",
      "Epoch 95/150\n",
      "29/29 [==============================] - 0s 752us/step - loss: 0.0223 - accuracy: 0.9862\n",
      "Epoch 96/150\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 97/150\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 98/150\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 99/150\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0171 - accuracy: 0.9931\n",
      "Epoch 101/150\n",
      "29/29 [==============================] - 0s 778us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "29/29 [==============================] - 0s 653us/step - loss: 0.0163 - accuracy: 0.9931\n",
      "Epoch 103/150\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0180 - accuracy: 0.9862\n",
      "Epoch 104/150\n",
      "29/29 [==============================] - 0s 648us/step - loss: 0.0151 - accuracy: 0.9931\n",
      "Epoch 105/150\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0184 - accuracy: 0.9862\n",
      "Epoch 106/150\n",
      "29/29 [==============================] - 0s 645us/step - loss: 0.0195 - accuracy: 0.9862\n",
      "Epoch 107/150\n",
      "29/29 [==============================] - 0s 764us/step - loss: 0.0151 - accuracy: 0.9931\n",
      "Epoch 108/150\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.0158 - accuracy: 0.9931\n",
      "Epoch 111/150\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "29/29 [==============================] - 0s 646us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0108 - accuracy: 0.9931\n",
      "Epoch 118/150\n",
      "29/29 [==============================] - 0s 719us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "29/29 [==============================] - 0s 719us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "29/29 [==============================] - 0s 625us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "29/29 [==============================] - 0s 654us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "29/29 [==============================] - 0s 768us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "29/29 [==============================] - 0s 707us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "29/29 [==============================] - 0s 755us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "29/29 [==============================] - 0s 784us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "29/29 [==============================] - 0s 667us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "29/29 [==============================] - 0s 743us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "29/29 [==============================] - 0s 737us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5c2525b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "epochs_list = [50,100,130,150]\n",
    "평가리스트 = []\n",
    "for i in epochs_list:\n",
    "    # 모델 설정\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                    optimizer='adam',\n",
    "                    metrics= ['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=i, batch_size=5)\n",
    "    fit_acc = history.history[\"accuracy\"][-1]\n",
    "    acc = model.evaluate(X_test, Y_test)[1]\n",
    "    result = fit_acc, acc\n",
    "    \n",
    "    평가리스트.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8758620619773865, 0.761904776096344),\n",
       " (0.9931034445762634, 0.8571428656578064),\n",
       " (1.0, 0.8095238208770752),\n",
       " (1.0, 0.8095238208770752)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "평가리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위에서 epoch이 100일 때 test acc 기준으로 가장 높음  \n",
    "> 이후에는 과적합되어 test acc가 낮아짐  \n",
    "> -> epoch 100이 여기선 best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"596\" alt=\"image\" src=\"https://user-images.githubusercontent.com/88031549/199867058-46c5af44-02fb-4044-b34b-8a963b0a0f06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 K-fold로 교차 검증  \n",
    "위에서는 0.3만큼만 test set으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 777us/step - loss: 0.2473 - accuracy: 0.5448\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 739us/step - loss: 0.2359 - accuracy: 0.6207\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 804us/step - loss: 0.2310 - accuracy: 0.6138\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.2215 - accuracy: 0.6966\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.2130 - accuracy: 0.7241\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.2041 - accuracy: 0.7241\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 716us/step - loss: 0.1952 - accuracy: 0.7241\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 763us/step - loss: 0.1882 - accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1809 - accuracy: 0.7586\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.1784 - accuracy: 0.7862\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.1703 - accuracy: 0.7862\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 658us/step - loss: 0.1681 - accuracy: 0.7793\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.1629 - accuracy: 0.7862\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 771us/step - loss: 0.1580 - accuracy: 0.7862\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.1541 - accuracy: 0.7931\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.1498 - accuracy: 0.8069\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1459 - accuracy: 0.8276\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1410 - accuracy: 0.8414\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.1426 - accuracy: 0.7931\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 737us/step - loss: 0.1358 - accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.1330 - accuracy: 0.8276\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.1323 - accuracy: 0.8483\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 649us/step - loss: 0.1299 - accuracy: 0.8483\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.1263 - accuracy: 0.8552\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1272 - accuracy: 0.8138\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 837us/step - loss: 0.1240 - accuracy: 0.8414\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.1219 - accuracy: 0.8483\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.1204 - accuracy: 0.8414\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 647us/step - loss: 0.1190 - accuracy: 0.8414\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.1226 - accuracy: 0.8414\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 650us/step - loss: 0.1207 - accuracy: 0.8414\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.1172 - accuracy: 0.8552\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 649us/step - loss: 0.1138 - accuracy: 0.8621\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.1147 - accuracy: 0.8276\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.1137 - accuracy: 0.8552\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 639us/step - loss: 0.1111 - accuracy: 0.8345\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.1102 - accuracy: 0.8690\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 654us/step - loss: 0.1092 - accuracy: 0.8552\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.1073 - accuracy: 0.8621\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.1089 - accuracy: 0.8621\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.1107 - accuracy: 0.8759\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.1074 - accuracy: 0.8414\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.1086 - accuracy: 0.8552\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.1042 - accuracy: 0.8690\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.1024 - accuracy: 0.8552\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.1028 - accuracy: 0.8690\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.1022 - accuracy: 0.8690\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 793us/step - loss: 0.0993 - accuracy: 0.8966\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0977 - accuracy: 0.8690\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 646us/step - loss: 0.0999 - accuracy: 0.8828\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 637us/step - loss: 0.0991 - accuracy: 0.8621\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0963 - accuracy: 0.8828\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0982 - accuracy: 0.8690\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0933 - accuracy: 0.8759\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0934 - accuracy: 0.8759\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 653us/step - loss: 0.0933 - accuracy: 0.8897\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0955 - accuracy: 0.8621\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 654us/step - loss: 0.0919 - accuracy: 0.8897\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0892 - accuracy: 0.8897\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 637us/step - loss: 0.0882 - accuracy: 0.8828\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 636us/step - loss: 0.0889 - accuracy: 0.8828\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0861 - accuracy: 0.8966\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.0852 - accuracy: 0.9034\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0829 - accuracy: 0.9103\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 647us/step - loss: 0.0887 - accuracy: 0.9103\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0819 - accuracy: 0.9034\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 833us/step - loss: 0.0794 - accuracy: 0.8966\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9103\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9034\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.8897\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0760 - accuracy: 0.9172\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 819us/step - loss: 0.0791 - accuracy: 0.9034\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0821 - accuracy: 0.8897\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 739us/step - loss: 0.0773 - accuracy: 0.9034\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 646us/step - loss: 0.0752 - accuracy: 0.9172\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 799us/step - loss: 0.0827 - accuracy: 0.8828\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 634us/step - loss: 0.0737 - accuracy: 0.9034\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0709 - accuracy: 0.9103\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0725 - accuracy: 0.8966\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0704 - accuracy: 0.9172\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 774us/step - loss: 0.0693 - accuracy: 0.9172\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 821us/step - loss: 0.0782 - accuracy: 0.8966\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.0784 - accuracy: 0.9034\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0713 - accuracy: 0.9172\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.0653 - accuracy: 0.9172\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0645 - accuracy: 0.9241\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0625 - accuracy: 0.9379\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 716us/step - loss: 0.0634 - accuracy: 0.9103\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.0601 - accuracy: 0.9379\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.0665 - accuracy: 0.9448\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 658us/step - loss: 0.0669 - accuracy: 0.9172\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0647 - accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0592 - accuracy: 0.9241\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.0573 - accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 731us/step - loss: 0.0551 - accuracy: 0.9448\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0545 - accuracy: 0.9586\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.0556 - accuracy: 0.9241\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 721us/step - loss: 0.0530 - accuracy: 0.9448\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0521 - accuracy: 0.9448\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0526 - accuracy: 0.9379\n",
      "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5e38f0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1903 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 809us/step - loss: 0.2548 - accuracy: 0.5379\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.2452 - accuracy: 0.5310\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.2405 - accuracy: 0.5310\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 760us/step - loss: 0.2358 - accuracy: 0.5310\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.2298 - accuracy: 0.5586\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.2251 - accuracy: 0.6069\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 745us/step - loss: 0.2192 - accuracy: 0.6207\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.2132 - accuracy: 0.6966\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 896us/step - loss: 0.2058 - accuracy: 0.6828\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 830us/step - loss: 0.1991 - accuracy: 0.7379\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 717us/step - loss: 0.1885 - accuracy: 0.7931\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 705us/step - loss: 0.1815 - accuracy: 0.7379\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 823us/step - loss: 0.1751 - accuracy: 0.7517\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 809us/step - loss: 0.1653 - accuracy: 0.7793\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1599 - accuracy: 0.7793\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.1543 - accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 730us/step - loss: 0.1505 - accuracy: 0.7862\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.1429 - accuracy: 0.7862\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 803us/step - loss: 0.1454 - accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.1353 - accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 771us/step - loss: 0.1310 - accuracy: 0.8276\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.1292 - accuracy: 0.8276\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.1251 - accuracy: 0.8345\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1211 - accuracy: 0.8552\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.1207 - accuracy: 0.8414\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 742us/step - loss: 0.1163 - accuracy: 0.8483\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8552\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 870us/step - loss: 0.1087 - accuracy: 0.8828\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 744us/step - loss: 0.1065 - accuracy: 0.8759\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.1081 - accuracy: 0.8552\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1053 - accuracy: 0.8828\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.1017 - accuracy: 0.8897\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 836us/step - loss: 0.0992 - accuracy: 0.8690\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0964 - accuracy: 0.8966\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 643us/step - loss: 0.0954 - accuracy: 0.8759\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.0909 - accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0889 - accuracy: 0.9034\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0873 - accuracy: 0.8759\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9034\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.0856 - accuracy: 0.9034\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0851 - accuracy: 0.8897\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 707us/step - loss: 0.0816 - accuracy: 0.9034\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 731us/step - loss: 0.0822 - accuracy: 0.8966\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0764 - accuracy: 0.9103\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0743 - accuracy: 0.9172\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.0724 - accuracy: 0.9172\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.0708 - accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0698 - accuracy: 0.9103\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0669 - accuracy: 0.9172\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 874us/step - loss: 0.0716 - accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9379\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9172\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9517\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 992us/step - loss: 0.0623 - accuracy: 0.9448\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9448\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0565 - accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.0552 - accuracy: 0.9448\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.0537 - accuracy: 0.9379\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0514 - accuracy: 0.9379\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9448\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0520 - accuracy: 0.9517\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0482 - accuracy: 0.9586\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0464 - accuracy: 0.9586\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 737us/step - loss: 0.0492 - accuracy: 0.9586\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.0453 - accuracy: 0.9517\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9655\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9724\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9655\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9586\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.0385 - accuracy: 0.9655\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 910us/step - loss: 0.0395 - accuracy: 0.9379\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0420 - accuracy: 0.9586\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0371 - accuracy: 0.9724\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0371 - accuracy: 0.9655\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.0364 - accuracy: 0.9655\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.0346 - accuracy: 0.9655\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.0318 - accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 964us/step - loss: 0.0342 - accuracy: 0.9586\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 996us/step - loss: 0.0324 - accuracy: 0.9655\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 795us/step - loss: 0.0331 - accuracy: 0.9655\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 850us/step - loss: 0.0328 - accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 864us/step - loss: 0.0275 - accuracy: 0.9862\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0254 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.0254 - accuracy: 0.9724\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0231 - accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 869us/step - loss: 0.0262 - accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 651us/step - loss: 0.0312 - accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0260 - accuracy: 0.9724\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 900us/step - loss: 0.0239 - accuracy: 0.9793\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.0200 - accuracy: 0.9931\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.0187 - accuracy: 0.9931\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0184 - accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0195 - accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0172 - accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0166 - accuracy: 0.9931\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 794us/step - loss: 0.2514 - accuracy: 0.4966\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 719us/step - loss: 0.2414 - accuracy: 0.5586\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 731us/step - loss: 0.2357 - accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.2277 - accuracy: 0.7103\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 730us/step - loss: 0.2201 - accuracy: 0.7241\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.2123 - accuracy: 0.7724\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.2055 - accuracy: 0.7586\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.1987 - accuracy: 0.7724\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.1930 - accuracy: 0.7448\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1889 - accuracy: 0.7724\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.1813 - accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.1778 - accuracy: 0.7931\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.1730 - accuracy: 0.7586\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1672 - accuracy: 0.7586\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 867us/step - loss: 0.1624 - accuracy: 0.7655\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 855us/step - loss: 0.1574 - accuracy: 0.7793\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.1534 - accuracy: 0.8069\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.1448 - accuracy: 0.8138\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1467 - accuracy: 0.8138\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1362 - accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.1328 - accuracy: 0.8552\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.1312 - accuracy: 0.8483\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.1265 - accuracy: 0.8552\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.1224 - accuracy: 0.8345\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 741us/step - loss: 0.1203 - accuracy: 0.8414\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.1172 - accuracy: 0.8759\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.1126 - accuracy: 0.8759\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.1075 - accuracy: 0.8966\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.1061 - accuracy: 0.8897\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.1064 - accuracy: 0.8828\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 653us/step - loss: 0.1063 - accuracy: 0.8621\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 731us/step - loss: 0.1018 - accuracy: 0.8966\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 743us/step - loss: 0.0965 - accuracy: 0.8897\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.8897\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9103\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0893 - accuracy: 0.8897\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 739us/step - loss: 0.0852 - accuracy: 0.9172\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0842 - accuracy: 0.9034\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0811 - accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0832 - accuracy: 0.9172\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.0807 - accuracy: 0.9103\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 902us/step - loss: 0.0769 - accuracy: 0.9103\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 759us/step - loss: 0.0784 - accuracy: 0.9034\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 754us/step - loss: 0.0761 - accuracy: 0.9103\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.0702 - accuracy: 0.9379\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0673 - accuracy: 0.9379\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0661 - accuracy: 0.9379\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.0633 - accuracy: 0.9241\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0601 - accuracy: 0.9448\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0631 - accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.0656 - accuracy: 0.9379\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0578 - accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0566 - accuracy: 0.9448\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 728us/step - loss: 0.0515 - accuracy: 0.9724\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.0513 - accuracy: 0.9793\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.0484 - accuracy: 0.9793\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9655\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 795us/step - loss: 0.0496 - accuracy: 0.9724\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 721us/step - loss: 0.0455 - accuracy: 0.9655\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0469 - accuracy: 0.9724\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.0409 - accuracy: 0.9862\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.0419 - accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0381 - accuracy: 0.9724\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 718us/step - loss: 0.0363 - accuracy: 0.9862\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.0390 - accuracy: 0.9931\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9793\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0322 - accuracy: 0.9931\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 742us/step - loss: 0.0331 - accuracy: 0.9862\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0339 - accuracy: 0.9862\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0348 - accuracy: 0.9862\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.0283 - accuracy: 0.9793\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0271 - accuracy: 0.9931\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0287 - accuracy: 0.9862\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0262 - accuracy: 0.9931\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0270 - accuracy: 0.9931\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 717us/step - loss: 0.0257 - accuracy: 0.9931\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9931\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9931\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 845us/step - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 846us/step - loss: 0.0195 - accuracy: 0.9931\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 901us/step - loss: 0.0233 - accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 862us/step - loss: 0.0229 - accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.0187 - accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 911us/step - loss: 0.0176 - accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0162 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.0154 - accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 883us/step - loss: 0.0180 - accuracy: 0.9931\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.0139 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 919us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 936us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 724us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0114 - accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 947us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0659 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.5241\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.2474 - accuracy: 0.5586\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5310\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.2408 - accuracy: 0.5931\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.2369 - accuracy: 0.6690\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.2312 - accuracy: 0.7103\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.2245 - accuracy: 0.7310\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.2183 - accuracy: 0.7655\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 843us/step - loss: 0.2110 - accuracy: 0.7517\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 770us/step - loss: 0.2053 - accuracy: 0.7517\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.1958 - accuracy: 0.7586\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.1899 - accuracy: 0.7517\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 944us/step - loss: 0.1834 - accuracy: 0.7517\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.1750 - accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.1693 - accuracy: 0.7724\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 863us/step - loss: 0.1609 - accuracy: 0.7931\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 862us/step - loss: 0.1554 - accuracy: 0.7931\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 654us/step - loss: 0.1484 - accuracy: 0.8069\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 800us/step - loss: 0.1479 - accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.1391 - accuracy: 0.8414\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.1345 - accuracy: 0.8414\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.1339 - accuracy: 0.8414\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.8414\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.1232 - accuracy: 0.8690\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.1258 - accuracy: 0.8138\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.1192 - accuracy: 0.8552\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 731us/step - loss: 0.1151 - accuracy: 0.8483\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8552\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8621\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.1138 - accuracy: 0.8414\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.1107 - accuracy: 0.8483\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.1060 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 753us/step - loss: 0.1033 - accuracy: 0.8828\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.1023 - accuracy: 0.8621\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.1010 - accuracy: 0.8621\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0978 - accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0950 - accuracy: 0.8828\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0946 - accuracy: 0.8897\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 728us/step - loss: 0.0924 - accuracy: 0.8759\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 809us/step - loss: 0.0945 - accuracy: 0.8897\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 766us/step - loss: 0.0920 - accuracy: 0.9034\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.8966\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.8828\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0870 - accuracy: 0.8897\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0828 - accuracy: 0.8966\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0819 - accuracy: 0.8828\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 845us/step - loss: 0.0797 - accuracy: 0.8966\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0798 - accuracy: 0.9034\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0769 - accuracy: 0.9034\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0803 - accuracy: 0.9103\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0771 - accuracy: 0.9103\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.0735 - accuracy: 0.9034\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9034\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 880us/step - loss: 0.0696 - accuracy: 0.9172\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 705us/step - loss: 0.0704 - accuracy: 0.8966\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0678 - accuracy: 0.9103\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.8966\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 828us/step - loss: 0.0662 - accuracy: 0.9034\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0648 - accuracy: 0.9241\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0626 - accuracy: 0.9241\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 790us/step - loss: 0.0602 - accuracy: 0.9034\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0596 - accuracy: 0.9241\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.0579 - accuracy: 0.9241\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.0553 - accuracy: 0.9241\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 815us/step - loss: 0.0562 - accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 852us/step - loss: 0.0533 - accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 755us/step - loss: 0.0501 - accuracy: 0.9379\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 906us/step - loss: 0.0512 - accuracy: 0.9586\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.0486 - accuracy: 0.9517\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0516 - accuracy: 0.9586\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.0453 - accuracy: 0.9655\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9586\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0475 - accuracy: 0.9448\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.0428 - accuracy: 0.9586\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0414 - accuracy: 0.9586\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.0421 - accuracy: 0.9655\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9586\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9724\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 908us/step - loss: 0.0369 - accuracy: 0.9586\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9724\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 856us/step - loss: 0.0317 - accuracy: 0.9793\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.0365 - accuracy: 0.9586\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0375 - accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0326 - accuracy: 0.9655\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0282 - accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0260 - accuracy: 0.9793\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 872us/step - loss: 0.0257 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 744us/step - loss: 0.0236 - accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9586\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 916us/step - loss: 0.0300 - accuracy: 0.9724\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 873us/step - loss: 0.0218 - accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.0203 - accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 914us/step - loss: 0.0178 - accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0187 - accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0181 - accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 946us/step - loss: 0.0160 - accuracy: 0.9931\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0244 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.2515 - accuracy: 0.4414\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 898us/step - loss: 0.2480 - accuracy: 0.5448\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 767us/step - loss: 0.2445 - accuracy: 0.5310\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.2380 - accuracy: 0.5517\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.2319 - accuracy: 0.6897\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.6966\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.7172\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 979us/step - loss: 0.1917 - accuracy: 0.7172\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 885us/step - loss: 0.1883 - accuracy: 0.7517\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 833us/step - loss: 0.1663 - accuracy: 0.7793\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.1606 - accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.7793\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.1490 - accuracy: 0.8138\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 987us/step - loss: 0.1446 - accuracy: 0.8207\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.8069\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 867us/step - loss: 0.1318 - accuracy: 0.8276\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 811us/step - loss: 0.1278 - accuracy: 0.8483\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 838us/step - loss: 0.1255 - accuracy: 0.8276\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1224 - accuracy: 0.8483\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 876us/step - loss: 0.1171 - accuracy: 0.8690\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.8345\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 761us/step - loss: 0.1143 - accuracy: 0.8759\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.1103 - accuracy: 0.8414\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.8897\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.8828\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 909us/step - loss: 0.1088 - accuracy: 0.8828\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.1074 - accuracy: 0.8483\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.8828\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 802us/step - loss: 0.0979 - accuracy: 0.8828\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9103\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.8966\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0905 - accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 747us/step - loss: 0.0881 - accuracy: 0.8966\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 742us/step - loss: 0.0866 - accuracy: 0.9034\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0832 - accuracy: 0.9172\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 739us/step - loss: 0.0867 - accuracy: 0.9241\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 931us/step - loss: 0.0848 - accuracy: 0.9103\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.0808 - accuracy: 0.9034\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.0873 - accuracy: 0.8690\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 744us/step - loss: 0.0797 - accuracy: 0.9034\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9103\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9379\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.0727 - accuracy: 0.9241\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9172\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0659 - accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 862us/step - loss: 0.0716 - accuracy: 0.9241\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 747us/step - loss: 0.0703 - accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 869us/step - loss: 0.0658 - accuracy: 0.9241\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 868us/step - loss: 0.0650 - accuracy: 0.9379\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.0602 - accuracy: 0.9379\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 797us/step - loss: 0.0611 - accuracy: 0.9379\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.0574 - accuracy: 0.9448\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 894us/step - loss: 0.0595 - accuracy: 0.9241\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9448\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9379\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 903us/step - loss: 0.0548 - accuracy: 0.9448\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9517\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9448\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.0462 - accuracy: 0.9517\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 797us/step - loss: 0.0468 - accuracy: 0.9448\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 718us/step - loss: 0.0478 - accuracy: 0.9379\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 718us/step - loss: 0.0413 - accuracy: 0.9655\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9724\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 842us/step - loss: 0.0425 - accuracy: 0.9517\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0461 - accuracy: 0.9655\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 857us/step - loss: 0.0374 - accuracy: 0.9517\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 716us/step - loss: 0.0356 - accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 773us/step - loss: 0.0400 - accuracy: 0.9586\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0358 - accuracy: 0.9655\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 754us/step - loss: 0.0341 - accuracy: 0.9586\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.0350 - accuracy: 0.9931\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.0350 - accuracy: 0.9586\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 964us/step - loss: 0.0335 - accuracy: 0.9724\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9793\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.0303 - accuracy: 0.9724\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9724\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9655\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 975us/step - loss: 0.0260 - accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.0226 - accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0223 - accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 744us/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0225 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.0279 - accuracy: 0.9793\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.0264 - accuracy: 0.9862\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.0230 - accuracy: 0.9793\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 815us/step - loss: 0.0181 - accuracy: 0.9931\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9931\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 892us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 869us/step - loss: 0.0169 - accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 970us/step - loss: 0.0144 - accuracy: 0.9931\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0478 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.4483\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.5793\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 894us/step - loss: 0.2378 - accuracy: 0.5931\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.2290 - accuracy: 0.6759\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.2214 - accuracy: 0.7241\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 759us/step - loss: 0.2134 - accuracy: 0.7517\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.2063 - accuracy: 0.7034\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 891us/step - loss: 0.1991 - accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.1921 - accuracy: 0.7517\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.1877 - accuracy: 0.7586\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.1800 - accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 831us/step - loss: 0.1755 - accuracy: 0.8207\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.7655\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.1656 - accuracy: 0.7862\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 871us/step - loss: 0.1625 - accuracy: 0.7517\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.1566 - accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 899us/step - loss: 0.1528 - accuracy: 0.8138\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 729us/step - loss: 0.1420 - accuracy: 0.8207\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.1397 - accuracy: 0.8207\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 701us/step - loss: 0.1390 - accuracy: 0.8207\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 763us/step - loss: 0.1361 - accuracy: 0.8276\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.1336 - accuracy: 0.8414\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.1333 - accuracy: 0.8207\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.1306 - accuracy: 0.8276\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 705us/step - loss: 0.1285 - accuracy: 0.8276\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1266 - accuracy: 0.8345\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 915us/step - loss: 0.1257 - accuracy: 0.8138\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.1276 - accuracy: 0.8069\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 860us/step - loss: 0.1229 - accuracy: 0.8552\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 919us/step - loss: 0.1217 - accuracy: 0.8414\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.8483\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.8483\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 732us/step - loss: 0.1174 - accuracy: 0.8207\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1166 - accuracy: 0.8345\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 856us/step - loss: 0.1157 - accuracy: 0.8345\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1146 - accuracy: 0.8483\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 862us/step - loss: 0.1158 - accuracy: 0.8621\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 728us/step - loss: 0.1198 - accuracy: 0.8621\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1137 - accuracy: 0.8276\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 755us/step - loss: 0.1156 - accuracy: 0.8345\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.8483\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.1102 - accuracy: 0.8345\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 966us/step - loss: 0.1101 - accuracy: 0.8483\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 819us/step - loss: 0.1099 - accuracy: 0.8483\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 814us/step - loss: 0.1068 - accuracy: 0.8552\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.8345\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.8483\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.8483\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.1038 - accuracy: 0.8621\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.1064 - accuracy: 0.8483\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 900us/step - loss: 0.1031 - accuracy: 0.8552\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.1041 - accuracy: 0.8621\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.1028 - accuracy: 0.8690\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 701us/step - loss: 0.1055 - accuracy: 0.8552\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1005 - accuracy: 0.8690\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.0991 - accuracy: 0.8621\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.0977 - accuracy: 0.8759\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0975 - accuracy: 0.8552\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 718us/step - loss: 0.0961 - accuracy: 0.8828\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0973 - accuracy: 0.9034\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 866us/step - loss: 0.0929 - accuracy: 0.8759\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0981 - accuracy: 0.8828\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 724us/step - loss: 0.0923 - accuracy: 0.8828\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 665us/step - loss: 0.0901 - accuracy: 0.8897\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0929 - accuracy: 0.8828\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.0908 - accuracy: 0.8828\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.8759\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9034\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0933 - accuracy: 0.8690\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0909 - accuracy: 0.8828\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 835us/step - loss: 0.0885 - accuracy: 0.8897\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0853 - accuracy: 0.8828\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.0949 - accuracy: 0.8483\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0841 - accuracy: 0.9103\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.0821 - accuracy: 0.8897\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 871us/step - loss: 0.0814 - accuracy: 0.8966\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0804 - accuracy: 0.8828\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0777 - accuracy: 0.9103\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0856 - accuracy: 0.8759\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.0852 - accuracy: 0.8897\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 868us/step - loss: 0.0823 - accuracy: 0.8897\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9172\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9241\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 753us/step - loss: 0.0717 - accuracy: 0.9172\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.0710 - accuracy: 0.9241\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 823us/step - loss: 0.0697 - accuracy: 0.9172\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0727 - accuracy: 0.9103\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 741us/step - loss: 0.0715 - accuracy: 0.9103\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 757us/step - loss: 0.0722 - accuracy: 0.9103\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0661 - accuracy: 0.9241\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0670 - accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0625 - accuracy: 0.9241\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 741us/step - loss: 0.0617 - accuracy: 0.9379\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 907us/step - loss: 0.0611 - accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9379\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9379\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1433 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 782us/step - loss: 0.2806 - accuracy: 0.4483\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.2376 - accuracy: 0.6069\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.2265 - accuracy: 0.6138\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 796us/step - loss: 0.2188 - accuracy: 0.6897\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.2088 - accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 757us/step - loss: 0.2012 - accuracy: 0.7310\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.1933 - accuracy: 0.7241\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.1872 - accuracy: 0.7586\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 850us/step - loss: 0.1816 - accuracy: 0.7241\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.1800 - accuracy: 0.7448\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.1718 - accuracy: 0.7931\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1696 - accuracy: 0.8069\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.1644 - accuracy: 0.7655\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 838us/step - loss: 0.1582 - accuracy: 0.7586\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.1537 - accuracy: 0.8276\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1486 - accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.1463 - accuracy: 0.8069\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.1386 - accuracy: 0.8069\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.1388 - accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.8414\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 761us/step - loss: 0.1274 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.1260 - accuracy: 0.8483\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1236 - accuracy: 0.8552\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 763us/step - loss: 0.1190 - accuracy: 0.8690\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.1203 - accuracy: 0.8207\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1152 - accuracy: 0.8759\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 727us/step - loss: 0.1120 - accuracy: 0.8690\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1080 - accuracy: 0.8690\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 729us/step - loss: 0.1067 - accuracy: 0.8828\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 753us/step - loss: 0.1105 - accuracy: 0.8621\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1076 - accuracy: 0.8828\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.1040 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 640us/step - loss: 0.0985 - accuracy: 0.8897\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0983 - accuracy: 0.8897\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 736us/step - loss: 0.0967 - accuracy: 0.8828\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0928 - accuracy: 0.8897\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0910 - accuracy: 0.9034\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.8897\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9172\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 752us/step - loss: 0.0873 - accuracy: 0.8897\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0909 - accuracy: 0.8828\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0844 - accuracy: 0.8759\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 834us/step - loss: 0.0875 - accuracy: 0.8759\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0813 - accuracy: 0.8897\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0761 - accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.0774 - accuracy: 0.9172\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.0757 - accuracy: 0.9172\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 814us/step - loss: 0.0730 - accuracy: 0.9241\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 856us/step - loss: 0.0696 - accuracy: 0.9379\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0720 - accuracy: 0.9172\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.0735 - accuracy: 0.9172\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.0711 - accuracy: 0.9241\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9172\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 752us/step - loss: 0.0626 - accuracy: 0.9517\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 731us/step - loss: 0.0642 - accuracy: 0.9517\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0623 - accuracy: 0.9586\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9448\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 894us/step - loss: 0.0642 - accuracy: 0.9379\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 882us/step - loss: 0.0574 - accuracy: 0.9517\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.0594 - accuracy: 0.9517\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9448\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 893us/step - loss: 0.0552 - accuracy: 0.9655\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 837us/step - loss: 0.0520 - accuracy: 0.9655\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 782us/step - loss: 0.0514 - accuracy: 0.9655\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0538 - accuracy: 0.9448\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.0515 - accuracy: 0.9517\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9655\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9586\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.0472 - accuracy: 0.9655\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 827us/step - loss: 0.0502 - accuracy: 0.9517\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 755us/step - loss: 0.0426 - accuracy: 0.9586\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0415 - accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.0458 - accuracy: 0.9448\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 920us/step - loss: 0.0447 - accuracy: 0.9586\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0390 - accuracy: 0.9724\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 866us/step - loss: 0.0442 - accuracy: 0.9517\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.0440 - accuracy: 0.9655\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.0388 - accuracy: 0.9655\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9793\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9724\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 742us/step - loss: 0.0339 - accuracy: 0.9793\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 843us/step - loss: 0.0363 - accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 768us/step - loss: 0.0376 - accuracy: 0.9724\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0305 - accuracy: 0.9793\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0320 - accuracy: 0.9793\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 757us/step - loss: 0.0296 - accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 776us/step - loss: 0.0269 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 842us/step - loss: 0.0281 - accuracy: 0.9724\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 645us/step - loss: 0.0272 - accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.0260 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 968us/step - loss: 0.0294 - accuracy: 0.9793\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 903us/step - loss: 0.0320 - accuracy: 0.9655\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.0218 - accuracy: 0.9793\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.0245 - accuracy: 0.9793\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 802us/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 781us/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.0198 - accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 886us/step - loss: 0.0195 - accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 875us/step - loss: 0.0186 - accuracy: 0.9931\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 829us/step - loss: 0.2455 - accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 845us/step - loss: 0.2322 - accuracy: 0.6414\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 784us/step - loss: 0.2271 - accuracy: 0.6690\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 767us/step - loss: 0.2186 - accuracy: 0.6897\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 853us/step - loss: 0.2089 - accuracy: 0.7034\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.7103\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7241\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.1799 - accuracy: 0.7793\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.1715 - accuracy: 0.7586\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.1693 - accuracy: 0.7586\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 859us/step - loss: 0.1610 - accuracy: 0.8138\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 756us/step - loss: 0.1568 - accuracy: 0.7862\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 707us/step - loss: 0.1525 - accuracy: 0.8069\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.1462 - accuracy: 0.8207\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 900us/step - loss: 0.1400 - accuracy: 0.8621\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.1368 - accuracy: 0.8138\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.8414\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.8552\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 901us/step - loss: 0.1206 - accuracy: 0.8690\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 742us/step - loss: 0.1173 - accuracy: 0.8759\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 752us/step - loss: 0.1164 - accuracy: 0.8552\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 701us/step - loss: 0.1118 - accuracy: 0.8828\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 951us/step - loss: 0.1080 - accuracy: 0.8966\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 897us/step - loss: 0.1087 - accuracy: 0.8552\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 905us/step - loss: 0.1041 - accuracy: 0.8897\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 805us/step - loss: 0.1009 - accuracy: 0.8828\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 941us/step - loss: 0.0975 - accuracy: 0.8690\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 883us/step - loss: 0.0952 - accuracy: 0.8897\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 792us/step - loss: 0.0977 - accuracy: 0.8897\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.8690\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 986us/step - loss: 0.0930 - accuracy: 0.8966\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0884 - accuracy: 0.9103\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 701us/step - loss: 0.0856 - accuracy: 0.8828\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0831 - accuracy: 0.9034\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 959us/step - loss: 0.0810 - accuracy: 0.8897\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.0783 - accuracy: 0.8966\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0779 - accuracy: 0.9034\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0752 - accuracy: 0.9241\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.0776 - accuracy: 0.8966\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.0733 - accuracy: 0.8966\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 727us/step - loss: 0.0711 - accuracy: 0.9172\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9034\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9241\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0635 - accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0635 - accuracy: 0.9379\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 767us/step - loss: 0.0631 - accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 887us/step - loss: 0.0600 - accuracy: 0.9172\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0574 - accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0609 - accuracy: 0.9448\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9379\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 778us/step - loss: 0.0568 - accuracy: 0.9241\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9448\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 871us/step - loss: 0.0499 - accuracy: 0.9586\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9517\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 817us/step - loss: 0.0479 - accuracy: 0.9655\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0493 - accuracy: 0.9448\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9517\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 971us/step - loss: 0.0452 - accuracy: 0.9586\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 922us/step - loss: 0.0444 - accuracy: 0.9517\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.0410 - accuracy: 0.9655\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9517\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 865us/step - loss: 0.0398 - accuracy: 0.9586\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 933us/step - loss: 0.0377 - accuracy: 0.9586\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0373 - accuracy: 0.9793\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 759us/step - loss: 0.0391 - accuracy: 0.9655\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9655\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 766us/step - loss: 0.0335 - accuracy: 0.9724\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.0333 - accuracy: 0.9655\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 864us/step - loss: 0.0367 - accuracy: 0.9586\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 938us/step - loss: 0.0302 - accuracy: 0.9793\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 870us/step - loss: 0.0295 - accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 833us/step - loss: 0.0333 - accuracy: 0.9724\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9793\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.0272 - accuracy: 0.9793\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 803us/step - loss: 0.0277 - accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9724\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9793\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9931\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 717us/step - loss: 0.0269 - accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 725us/step - loss: 0.0230 - accuracy: 0.9793\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 667us/step - loss: 0.0275 - accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.0265 - accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 724us/step - loss: 0.0205 - accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0185 - accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 747us/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 828us/step - loss: 0.0181 - accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 827us/step - loss: 0.0212 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 923us/step - loss: 0.0223 - accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.0184 - accuracy: 0.9931\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 819us/step - loss: 0.0192 - accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 849us/step - loss: 0.0142 - accuracy: 0.9931\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 766us/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0798 - accuracy: 0.9048\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 864us/step - loss: 0.2505 - accuracy: 0.4621\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 791us/step - loss: 0.2397 - accuracy: 0.6483\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.2365 - accuracy: 0.6483\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.2290 - accuracy: 0.6690\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.2237 - accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 815us/step - loss: 0.2153 - accuracy: 0.6828\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.2064 - accuracy: 0.7448\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.1972 - accuracy: 0.7724\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 912us/step - loss: 0.1877 - accuracy: 0.7172\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.1838 - accuracy: 0.7655\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.7793\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.1656 - accuracy: 0.7793\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.7448\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.1544 - accuracy: 0.8138\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 902us/step - loss: 0.1488 - accuracy: 0.8207\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.1439 - accuracy: 0.8207\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 738us/step - loss: 0.1375 - accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.1402 - accuracy: 0.8069\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.1300 - accuracy: 0.8552\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 785us/step - loss: 0.1261 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.8690\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.8690\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 922us/step - loss: 0.1155 - accuracy: 0.8897\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.8690\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8690\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.8690\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 924us/step - loss: 0.1022 - accuracy: 0.9034\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.0996 - accuracy: 0.8966\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 674us/step - loss: 0.1020 - accuracy: 0.8828\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.1006 - accuracy: 0.8759\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9034\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.8966\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 958us/step - loss: 0.0912 - accuracy: 0.9034\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 758us/step - loss: 0.0853 - accuracy: 0.8897\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 903us/step - loss: 0.0831 - accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9034\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 957us/step - loss: 0.0765 - accuracy: 0.9172\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 842us/step - loss: 0.0736 - accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 838us/step - loss: 0.0774 - accuracy: 0.9034\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 917us/step - loss: 0.0746 - accuracy: 0.9103\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9241\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9034\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 726us/step - loss: 0.0665 - accuracy: 0.9172\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 705us/step - loss: 0.0596 - accuracy: 0.9517\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0600 - accuracy: 0.9241\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0576 - accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 833us/step - loss: 0.0570 - accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0530 - accuracy: 0.9448\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 627us/step - loss: 0.0555 - accuracy: 0.9586\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 742us/step - loss: 0.0575 - accuracy: 0.9103\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 959us/step - loss: 0.0529 - accuracy: 0.9379\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0450 - accuracy: 0.9586\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.0450 - accuracy: 0.9517\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 685us/step - loss: 0.0413 - accuracy: 0.9724\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.0436 - accuracy: 0.9517\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0402 - accuracy: 0.9655\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 817us/step - loss: 0.0388 - accuracy: 0.9655\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.0363 - accuracy: 0.9655\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.0349 - accuracy: 0.9793\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 768us/step - loss: 0.0355 - accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9724\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 930us/step - loss: 0.0320 - accuracy: 0.9655\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.0321 - accuracy: 0.9724\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.0303 - accuracy: 0.9862\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0265 - accuracy: 0.9931\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 738us/step - loss: 0.0276 - accuracy: 0.9793\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.0270 - accuracy: 0.9931\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.0331 - accuracy: 0.9793\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0239 - accuracy: 0.9931\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 946us/step - loss: 0.0235 - accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 644us/step - loss: 0.0289 - accuracy: 0.9724\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 720us/step - loss: 0.0202 - accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0210 - accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 671us/step - loss: 0.0199 - accuracy: 0.9931\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 804us/step - loss: 0.0190 - accuracy: 0.9931\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0192 - accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0165 - accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 747us/step - loss: 0.0182 - accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 799us/step - loss: 0.0163 - accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 736us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 808us/step - loss: 0.0133 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.0135 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0157 - accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0132 - accuracy: 0.9931\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 779us/step - loss: 0.0142 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9931\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 908us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 824us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 938us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.2548 - accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 829us/step - loss: 0.2427 - accuracy: 0.5310\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 699us/step - loss: 0.2391 - accuracy: 0.5310\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 808us/step - loss: 0.2331 - accuracy: 0.5448\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 645us/step - loss: 0.2295 - accuracy: 0.6621\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.2251 - accuracy: 0.6897\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.2194 - accuracy: 0.6828\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.2144 - accuracy: 0.7310\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 730us/step - loss: 0.2095 - accuracy: 0.7034\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.2048 - accuracy: 0.7448\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 918us/step - loss: 0.1979 - accuracy: 0.7724\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.7724\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.1869 - accuracy: 0.7724\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 801us/step - loss: 0.1806 - accuracy: 0.7586\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.1757 - accuracy: 0.8207\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 733us/step - loss: 0.1677 - accuracy: 0.7724\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 743us/step - loss: 0.1626 - accuracy: 0.7931\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.1546 - accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1529 - accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1459 - accuracy: 0.8069\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.1408 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.1394 - accuracy: 0.8207\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.1332 - accuracy: 0.8345\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.8207\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.8276\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.1232 - accuracy: 0.8552\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.1197 - accuracy: 0.8276\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.1150 - accuracy: 0.8828\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 970us/step - loss: 0.1128 - accuracy: 0.8345\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 794us/step - loss: 0.1136 - accuracy: 0.8552\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 828us/step - loss: 0.1132 - accuracy: 0.8276\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.1065 - accuracy: 0.8897\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.8621\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.8828\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.8966\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 980us/step - loss: 0.0931 - accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.8897\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9172\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 930us/step - loss: 0.0848 - accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.0831 - accuracy: 0.9241\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.8897\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9034\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.8897\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.0755 - accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.0712 - accuracy: 0.9379\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0713 - accuracy: 0.9241\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 700us/step - loss: 0.0673 - accuracy: 0.9379\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 745us/step - loss: 0.0668 - accuracy: 0.9241\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0615 - accuracy: 0.9448\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.0649 - accuracy: 0.9379\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.0639 - accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9517\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.0533 - accuracy: 0.9586\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.0540 - accuracy: 0.9655\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0513 - accuracy: 0.9586\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.0512 - accuracy: 0.9517\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 793us/step - loss: 0.0504 - accuracy: 0.9586\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 724us/step - loss: 0.0490 - accuracy: 0.9586\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0460 - accuracy: 0.9586\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 884us/step - loss: 0.0453 - accuracy: 0.9655\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9448\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 811us/step - loss: 0.0408 - accuracy: 0.9655\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 806us/step - loss: 0.0393 - accuracy: 0.9724\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0420 - accuracy: 0.9724\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.0397 - accuracy: 0.9655\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 692us/step - loss: 0.0346 - accuracy: 0.9724\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 831us/step - loss: 0.0362 - accuracy: 0.9724\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0340 - accuracy: 0.9793\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0385 - accuracy: 0.9724\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 922us/step - loss: 0.0312 - accuracy: 0.9862\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9586\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9793\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9793\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.0263 - accuracy: 0.9931\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 738us/step - loss: 0.0268 - accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 987us/step - loss: 0.0247 - accuracy: 0.9931\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 914us/step - loss: 0.0232 - accuracy: 0.9793\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 954us/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 3s 108ms/step - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 760us/step - loss: 0.0176 - accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9862\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9793\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9931\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9931\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9931\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9931\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0664 - accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "#빈 acc 배열\n",
    "accuracy = []\n",
    "\n",
    "# 모델의 설정, 컴파일, 실행\n",
    "for train, test in skf.split(X, Y):\n",
    "    # 모델 설정\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                    optimizer='adam',\n",
    "                    metrics= ['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=5)\n",
    "    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n",
    "    accuracy.append(k_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10번(n_fold)의 테스트 결과값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10 fold accuracy: ['0.7619', '1.0000', '0.9524', '0.9524', '0.9524', '0.7619', '1.0000', '0.9048', '1.0000', '0.9000']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n %.f fold accuracy:\" % n_fold, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. 실습 : Wine 데이터로 베스트 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
       "0               7.4             0.700         0.00  ...       0.56      9.4        5\n",
       "1               7.8             0.880         0.00  ...       0.68      9.8        5\n",
       "2               7.8             0.760         0.04  ...       0.65      9.8        5\n",
       "3              11.2             0.280         0.56  ...       0.58      9.8        6\n",
       "4               7.4             0.700         0.00  ...       0.56      9.4        5\n",
       "...             ...               ...          ...  ...        ...      ...      ...\n",
       "1594            6.2             0.600         0.08  ...       0.58     10.5        5\n",
       "1595            5.9             0.550         0.10  ...       0.76     11.2        6\n",
       "1596            6.3             0.510         0.13  ...       0.75     11.0        6\n",
       "1597            5.9             0.645         0.12  ...       0.71     10.2        5\n",
       "1598            6.0             0.310         0.47  ...       0.66     11.0        6\n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df = pd.read_csv(\"../datasets/winequality-red.csv\", delimiter=\";\")\n",
    "white_df = pd.read_csv(\"../datasets/winequality-white.csv\", delimiter=\";\")\n",
    "red_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling(Red=1 / White=0) & concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df['label'] = list(map(lambda x: 1, range(len(red_df))))\n",
    "white_df['label'] = list(map(lambda x: 0, range(len(white_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  label\n",
       "0               7.4              0.70         0.00  ...      9.4        5      1\n",
       "1               7.8              0.88         0.00  ...      9.8        5      1\n",
       "2               7.8              0.76         0.04  ...      9.8        5      1\n",
       "3              11.2              0.28         0.56  ...      9.8        6      1\n",
       "4               7.4              0.70         0.00  ...      9.4        5      1\n",
       "...             ...               ...          ...  ...      ...      ...    ...\n",
       "4893            6.2              0.21         0.29  ...     11.2        6      0\n",
       "4894            6.6              0.32         0.36  ...      9.6        5      0\n",
       "4895            6.5              0.24         0.19  ...      9.4        6      0\n",
       "4896            5.5              0.29         0.30  ...     12.8        7      0\n",
       "4897            6.0              0.21         0.38  ...     11.8        6      0\n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.concat([red_df , white_df])\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 752us/step - loss: 0.2492 - accuracy: 0.5379\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 855us/step - loss: 0.2442 - accuracy: 0.5724\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 750us/step - loss: 0.2408 - accuracy: 0.5586\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 921us/step - loss: 0.2324 - accuracy: 0.6828\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 719us/step - loss: 0.2239 - accuracy: 0.7103\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 760us/step - loss: 0.2152 - accuracy: 0.7310\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 709us/step - loss: 0.2052 - accuracy: 0.7034\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.1960 - accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 881us/step - loss: 0.1865 - accuracy: 0.7310\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.1818 - accuracy: 0.7586\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.1733 - accuracy: 0.8276\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 760us/step - loss: 0.1697 - accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1667 - accuracy: 0.8138\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 698us/step - loss: 0.1594 - accuracy: 0.7793\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.1536 - accuracy: 0.7931\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 721us/step - loss: 0.1478 - accuracy: 0.8414\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1451 - accuracy: 0.8345\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 707us/step - loss: 0.1388 - accuracy: 0.8414\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 642us/step - loss: 0.1423 - accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 651us/step - loss: 0.1317 - accuracy: 0.8690\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.1288 - accuracy: 0.8690\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 649us/step - loss: 0.1265 - accuracy: 0.8690\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1218 - accuracy: 0.8690\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.1190 - accuracy: 0.8828\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.1202 - accuracy: 0.8414\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.1148 - accuracy: 0.8690\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.1126 - accuracy: 0.8621\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 687us/step - loss: 0.1096 - accuracy: 0.8690\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 678us/step - loss: 0.1075 - accuracy: 0.8759\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.1102 - accuracy: 0.8552\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.1080 - accuracy: 0.8552\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.1029 - accuracy: 0.8759\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 672us/step - loss: 0.1003 - accuracy: 0.8828\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 966us/step - loss: 0.1013 - accuracy: 0.8621\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 667us/step - loss: 0.0971 - accuracy: 0.8690\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 656us/step - loss: 0.0957 - accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 644us/step - loss: 0.0932 - accuracy: 0.8897\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0921 - accuracy: 0.8897\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0902 - accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0924 - accuracy: 0.8897\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 652us/step - loss: 0.0902 - accuracy: 0.8897\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0880 - accuracy: 0.9034\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0891 - accuracy: 0.8828\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 681us/step - loss: 0.0854 - accuracy: 0.9103\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 690us/step - loss: 0.0818 - accuracy: 0.9103\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.0798 - accuracy: 0.9103\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 708us/step - loss: 0.0794 - accuracy: 0.9034\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 661us/step - loss: 0.0793 - accuracy: 0.9034\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 667us/step - loss: 0.0746 - accuracy: 0.9172\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0810 - accuracy: 0.9103\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 666us/step - loss: 0.0781 - accuracy: 0.9172\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 683us/step - loss: 0.0736 - accuracy: 0.9172\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.0733 - accuracy: 0.9103\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 648us/step - loss: 0.0685 - accuracy: 0.9241\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0709 - accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 760us/step - loss: 0.0672 - accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 777us/step - loss: 0.0686 - accuracy: 0.9172\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 670us/step - loss: 0.0678 - accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0656 - accuracy: 0.9379\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 706us/step - loss: 0.0640 - accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 651us/step - loss: 0.0616 - accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0620 - accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 648us/step - loss: 0.0606 - accuracy: 0.9379\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0571 - accuracy: 0.9448\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 649us/step - loss: 0.0579 - accuracy: 0.9448\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 658us/step - loss: 0.0576 - accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0528 - accuracy: 0.9379\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0550 - accuracy: 0.9448\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0533 - accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0574 - accuracy: 0.9448\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0504 - accuracy: 0.9379\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0487 - accuracy: 0.9379\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 740us/step - loss: 0.0530 - accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0490 - accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 882us/step - loss: 0.0442 - accuracy: 0.9379\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 741us/step - loss: 0.0464 - accuracy: 0.9379\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.0451 - accuracy: 0.9448\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0425 - accuracy: 0.9517\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.0433 - accuracy: 0.9586\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.0406 - accuracy: 0.9586\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.0383 - accuracy: 0.9586\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0442 - accuracy: 0.9517\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 701us/step - loss: 0.0423 - accuracy: 0.9586\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0381 - accuracy: 0.9379\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0346 - accuracy: 0.9724\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.0318 - accuracy: 0.9655\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 675us/step - loss: 0.0330 - accuracy: 0.9793\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0326 - accuracy: 0.9655\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 688us/step - loss: 0.0304 - accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.0356 - accuracy: 0.9724\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 657us/step - loss: 0.0358 - accuracy: 0.9586\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 660us/step - loss: 0.0334 - accuracy: 0.9655\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.0318 - accuracy: 0.9724\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 693us/step - loss: 0.0248 - accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 646us/step - loss: 0.0257 - accuracy: 0.9793\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.0233 - accuracy: 0.9862\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 689us/step - loss: 0.0238 - accuracy: 0.9793\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 664us/step - loss: 0.0246 - accuracy: 0.9793\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 703us/step - loss: 0.0224 - accuracy: 0.9793\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 647us/step - loss: 0.0211 - accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5b223e680>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics= ['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 학습 도중 모델 저장 & 조기종료 (in 학습)\n",
    "**-> 과적합 전의 모델을 사용할 수 있도록**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장 폴더 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./model/\"\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장 조건 설정\n",
    "> checkpointer : 모델 중간중간 저장  \n",
    "> early_stopping_callback : loss변동이 없으면 조기종료  \n",
    "> - patience가 100이라면 epoch이 100 돌아갈 동안 loss가 변동이 없다면 조기종료시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 실행 및 저장\n",
    "> \"collback\"이란, 함수의 파라미터 안에 다시 함수를 입력할 떄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2656e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2656e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.7391\n",
      "Epoch 2/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2644e-04 - accuracy: 1.0000\n",
      "Epoch 2: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2644e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.7391\n",
      "Epoch 3/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2632e-04 - accuracy: 1.0000\n",
      "Epoch 3: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2632e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.7391\n",
      "Epoch 4/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2622e-04 - accuracy: 1.0000\n",
      "Epoch 4: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2622e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 5/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2610e-04 - accuracy: 1.0000\n",
      "Epoch 5: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2610e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.7391\n",
      "Epoch 6/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2599e-04 - accuracy: 1.0000\n",
      "Epoch 6: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2599e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.7391\n",
      "Epoch 7/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2590e-04 - accuracy: 1.0000\n",
      "Epoch 7: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2590e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 8/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2579e-04 - accuracy: 1.0000\n",
      "Epoch 8: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2579e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 9/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2567e-04 - accuracy: 1.0000\n",
      "Epoch 9: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2567e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 10/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2556e-04 - accuracy: 1.0000\n",
      "Epoch 10: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2556e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 11/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2545e-04 - accuracy: 1.0000\n",
      "Epoch 11: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2545e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 12/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2535e-04 - accuracy: 1.0000\n",
      "Epoch 12: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2535e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 13/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2524e-04 - accuracy: 1.0000\n",
      "Epoch 13: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2524e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 14/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2513e-04 - accuracy: 1.0000\n",
      "Epoch 14: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2513e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 15/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2503e-04 - accuracy: 1.0000\n",
      "Epoch 15: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2503e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 16/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2492e-04 - accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2492e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 17/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2480e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2480e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 18/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2470e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2470e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.7391\n",
      "Epoch 19/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2460e-04 - accuracy: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2460e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 20/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2449e-04 - accuracy: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2449e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 21/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2438e-04 - accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2438e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 22/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2428e-04 - accuracy: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2428e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 23/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2417e-04 - accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2417e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 24/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2406e-04 - accuracy: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2406e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 25/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2396e-04 - accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2396e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 26/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2385e-04 - accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2385e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 27/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2374e-04 - accuracy: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 28/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2364e-04 - accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2364e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 29/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2353e-04 - accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2353e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 30/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2342e-04 - accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2342e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.7391\n",
      "Epoch 31/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2332e-04 - accuracy: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2332e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 32/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2322e-04 - accuracy: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2322e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 33/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2311e-04 - accuracy: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2311e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 34/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2301e-04 - accuracy: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2301e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 35/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2290e-04 - accuracy: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2290e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 36/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2280e-04 - accuracy: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2280e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.7391\n",
      "Epoch 37/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2270e-04 - accuracy: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2270e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 38/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2258e-04 - accuracy: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2258e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 39/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2248e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2248e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 40/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2238e-04 - accuracy: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2238e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 41/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2227e-04 - accuracy: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2227e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 42/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2218e-04 - accuracy: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2218e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 43/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2208e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2208e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 44/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2195e-04 - accuracy: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2195e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 45/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2186e-04 - accuracy: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2186e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 46/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2176e-04 - accuracy: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2176e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 47/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2166e-04 - accuracy: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2166e-04 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.7391\n",
      "Epoch 48/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2155e-04 - accuracy: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2155e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 49/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2146e-04 - accuracy: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2146e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 50/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2136e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2136e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 51/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2124e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2124e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 52/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2114e-04 - accuracy: 1.0000\n",
      "Epoch 52: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2114e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 53/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2105e-04 - accuracy: 1.0000\n",
      "Epoch 53: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2105e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 54/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2093e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2093e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 55/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2084e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 56/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2074e-04 - accuracy: 1.0000\n",
      "Epoch 56: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2074e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 57/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2063e-04 - accuracy: 1.0000\n",
      "Epoch 57: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2063e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 58/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2052e-04 - accuracy: 1.0000\n",
      "Epoch 58: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2052e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 59/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2041e-04 - accuracy: 1.0000\n",
      "Epoch 59: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2041e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 60/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2032e-04 - accuracy: 1.0000\n",
      "Epoch 60: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2032e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 61/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2022e-04 - accuracy: 1.0000\n",
      "Epoch 61: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2022e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 62/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2010e-04 - accuracy: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2010e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.7391\n",
      "Epoch 63/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2003e-04 - accuracy: 1.0000\n",
      "Epoch 63: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2003e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 64/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1992e-04 - accuracy: 1.0000\n",
      "Epoch 64: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1992e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 65/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1981e-04 - accuracy: 1.0000\n",
      "Epoch 65: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1981e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 66/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1970e-04 - accuracy: 1.0000\n",
      "Epoch 66: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1970e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 67/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1960e-04 - accuracy: 1.0000\n",
      "Epoch 67: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1960e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 68/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1950e-04 - accuracy: 1.0000\n",
      "Epoch 68: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1950e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 69/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1939e-04 - accuracy: 1.0000\n",
      "Epoch 69: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1939e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.7391\n",
      "Epoch 70/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1929e-04 - accuracy: 1.0000\n",
      "Epoch 70: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1929e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 71/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1919e-04 - accuracy: 1.0000\n",
      "Epoch 71: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1919e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 72/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1909e-04 - accuracy: 1.0000\n",
      "Epoch 72: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1909e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 73/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1899e-04 - accuracy: 1.0000\n",
      "Epoch 73: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1899e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 74/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1889e-04 - accuracy: 1.0000\n",
      "Epoch 74: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1889e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 75/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1879e-04 - accuracy: 1.0000\n",
      "Epoch 75: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1879e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 76/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1868e-04 - accuracy: 1.0000\n",
      "Epoch 76: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1868e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 77/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1860e-04 - accuracy: 1.0000\n",
      "Epoch 77: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1860e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 78/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1849e-04 - accuracy: 1.0000\n",
      "Epoch 78: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1849e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 79/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1838e-04 - accuracy: 1.0000\n",
      "Epoch 79: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1838e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 80/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1829e-04 - accuracy: 1.0000\n",
      "Epoch 80: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1829e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 81/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1820e-04 - accuracy: 1.0000\n",
      "Epoch 81: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1820e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 82/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1810e-04 - accuracy: 1.0000\n",
      "Epoch 82: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1810e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.7391\n",
      "Epoch 83/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1798e-04 - accuracy: 1.0000\n",
      "Epoch 83: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1798e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 84/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1790e-04 - accuracy: 1.0000\n",
      "Epoch 84: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1790e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 85/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1781e-04 - accuracy: 1.0000\n",
      "Epoch 85: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1781e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 86/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1770e-04 - accuracy: 1.0000\n",
      "Epoch 86: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1770e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 87/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1758e-04 - accuracy: 1.0000\n",
      "Epoch 87: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1758e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 88/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1750e-04 - accuracy: 1.0000\n",
      "Epoch 88: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1750e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 89/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1742e-04 - accuracy: 1.0000\n",
      "Epoch 89: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1742e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 90/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1732e-04 - accuracy: 1.0000\n",
      "Epoch 90: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1732e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 91/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1720e-04 - accuracy: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1720e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 92/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1708e-04 - accuracy: 1.0000\n",
      "Epoch 92: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1708e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 93/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1700e-04 - accuracy: 1.0000\n",
      "Epoch 93: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1700e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.7391\n",
      "Epoch 94/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1690e-04 - accuracy: 1.0000\n",
      "Epoch 94: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1690e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 95/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1680e-04 - accuracy: 1.0000\n",
      "Epoch 95: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1680e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 96/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1670e-04 - accuracy: 1.0000\n",
      "Epoch 96: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1670e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 97/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1660e-04 - accuracy: 1.0000\n",
      "Epoch 97: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1660e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 98/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1651e-04 - accuracy: 1.0000\n",
      "Epoch 98: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1651e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 99/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1640e-04 - accuracy: 1.0000\n",
      "Epoch 99: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1640e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 100/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1630e-04 - accuracy: 1.0000\n",
      "Epoch 100: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1630e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n",
      "Epoch 101/3500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1621e-04 - accuracy: 1.0000\n",
      "Epoch 101: val_loss did not improve from 0.00859\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1621e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.7391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5f1a25510>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback o\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500, callbacks=[early_stopping_callback ,checkpointer])\n",
    "\n",
    "# callback x\n",
    "# history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Plot : 정확도 & 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트셋으로 실험 결과의 오차값을 저장\n",
    "y_vloss =history.history[\"val_loss\"]\n",
    "\n",
    "# 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history[\"accuracy\"]\n",
    "\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3) # 정확도 : 파랑\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3) # 오차 : 빨강\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callback 없을 때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"544\" alt=\"image\" src=\"https://user-images.githubusercontent.com/88031549/199889081-c3a03941-cfbd-4198-8d82-f4d52d716236.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "끝!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d1ee4cf14d021861378c31d674abc774f58069cf7587f114521239d6c617ed3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
