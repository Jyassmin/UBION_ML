{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 : Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[회귀]**  \n",
    "ㅇ 단일회귀(독립변수가 x1 하나일 때)  \n",
    "- 단항식 : y를 직선으로 회귀 가능할 때 y=Wx1 + c 직선으로 회귀\n",
    "- 다항식 : y가 직선이 아닌 곡선으로 plot될 때 독립변수 x1 하나는 직선이라 회귀가 불가능. 이를 제곱하여 2차항으로 만들어 w1^2 * x1^2 + w2x1 + c 곡선으로 회귀한다.\n",
    "<br><br>  \n",
    " \n",
    "ㅇ 다중회귀(독립변수가 두개 이상)   \n",
    "- 만약 독립변수 2개, 종속 1개 이면 plot했을 때 3차원이다. \n",
    "- y가 어느 한 평면으로 회귀 가능한 data를 가진다면, 독립변수 2개로 평면을 만들어 회귀한다.\n",
    "- y가 평면으로 회귀 불가능한 Data를 가진다면, 폴리노미얼(다항식) 방식으로 제곱하거나 해서 곡선평명을 만들어 회귀한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ 단어정리 ]**    \n",
    "ㅇ Epoch : 회귀계수 업데이트한 횟수.  \n",
    "ㅇ Learning Rate : 회귀계수 찾는 거리.  \n",
    "ㅇ RSS(RESIDUAL SUM OF SQUARES) : 잔차 제곱의 합  \n",
    "ㄴ 얘가 cost funtion. 이 값을 낮추는 방향으로 회귀계수 수정하다가 0이 되거나 변함이 미미할 때 회귀 끝.  \n",
    "ㅇ MSE(mean squared error) : 잔차 제곱의 평균값(RSS/n).  \n",
    "ㅇ RMSE(root MSE) : MSE에 root.  \n",
    "ㅇ MAE(mean absolure erroe) : 잔차 절댓값의 평균.  \n",
    "ㅇ R^2 : 분산기반 평가지표. 예측값 분산/ 실제값 분산.  \n",
    "![스크린샷 2022-10-20 오전 10 52 43](https://user-images.githubusercontent.com/88031549/196837524-7148ca56-8957-48ac-b912-64bea03fae8c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ 릿지, 라쏘, 엘라스틱넷 ]**  \n",
    "L2 규제는 rss최적화.  \n",
    "L1 은 W를 0으로 만듦으로서 상관성이 낮은 독립변수를 제거하는 기능이 있음.\n",
    "\n",
    "릿지(L2), 라쏘(L1) : 오버피팅 방지, 다중공선성 방지  \n",
    "엘라스틱넷 : L1, L2 결합  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ploynomial 회귀 계수\n",
      " [[0.   0.02 0.02 0.05 0.07 0.1  0.1  0.14 0.22 0.31]\n",
      " [0.   0.06 0.06 0.11 0.17 0.23 0.23 0.34 0.51 0.74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import  LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def polynomial_func(X):\n",
    "    y = 1 + 2*X + X**2 + X**3\n",
    "    return y\n",
    "\n",
    "model = Pipeline([(\"poly\", PolynomialFeatures(degree=3)),\n",
    "                (\"linear\", LinearRegression())])\n",
    "\n",
    "X = np.arange(4).reshape(2,2)\n",
    "y = polynomial_func(X)\n",
    "\n",
    "model = model.fit(X,y)\n",
    "print(\"Ploynomial 회귀 계수\\n\", np.round(model.named_steps[\"linear\"].coef_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 다항회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y data가 한 선형에 있지 않을 때 독립변수 x를 폴리노미얼방식을 적용해 회귀할 수 있도록 한다.  \n",
    "그렇다고 차수(Degree)를 너무 높여서 회귀하게 되면 과대적합의 문제가 발생한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ 편향(error)-분산(회귀변동성) trade off ]**  \n",
    "ㅇ 과소적합 : 편향 높고, 분산 낮고   \n",
    "ㅇ 과대적합 : 편향 낮고, 분산 높고   \n",
    "\n",
    "![스크린샷 2022-10-20 오후 1 19 26](https://user-images.githubusercontent.com/88031549/196855510-5c38f307-300b-4e84-8648-028ac890eb90.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ L1, L2 규제 ]**  \n",
    "RSS(오차)를 최소화 하기 위해 회귀 계수를 계속 높이면은 과대적합이 발생한다.  \n",
    "그래서 RSS최소화와 더불어 회귀계수 크기를 밸런스 있게 제어하는 것이 필요.  \n",
    "이를 위해서 alpha 개념이 등장한다.  \n",
    "<br><br>\n",
    "\"비용 함수 목표 = Min(RSS(W) + alpha*||W||^2)\"\n",
    "alpha = 0 일 때 : W가 아무리 커도 0이되어, RSS(W)를 최소화 시켜 비용함수를 낮춤.  \n",
    "alpha = 무한대 일 때 : alpha*||W||^2가 무한대가 되므로, W을 0에 가깝게 최소화하여 비용함수를 낮춤.  \n",
    "<br><br>\n",
    "- L2 규제 : W의 제곱에 대해 페널티를 부여. -> 이를 적용한 회귀가 **릿지(Ridge)**.  \n",
    "- L1 규제 : W의 절댓값에 대해 페널티를 부여. -> 이를 적용한 회귀가 **라쏘(Lasso)**.  \n",
    "  - L1규제의 경우 영향력이 크지 않은 회귀 계수 값을 0으로 변환한다.  \n",
    "- L1, L2 결합: L1규제로 피처의 개수를 줄이고 , L2규제로 계수 값의 크기를 조정한다.\n",
    "  - -> 이를 적용한 회귀가 **엘라스틱넷(ElasticNet)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "그럼\n",
    "L1은 알파를 0으로하여 영향력이 크지 않은 회귀 계수 값을 0으로..?  \n",
    "근데 한 회귀식에서 비용함수는 하나인데 어떻게 부분적으로 영향력이 크지 않은 회귀 계수를 0으로 바꾸지??\n",
    "\n",
    "L2는 알파를 무한대로하여 계수값 낮춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c97f18ea1c0f4969cf594a5df9f14ba2a838cf106fc5300ddecce29d9d6f0c71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
